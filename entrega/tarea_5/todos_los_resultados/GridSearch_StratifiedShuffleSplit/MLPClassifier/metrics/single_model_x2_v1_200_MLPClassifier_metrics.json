{
  "experiment_info": {
    "type": "single_model_grid_search",
    "model_name": "MLPClassifier",
    "n_components": 200,
    "ratio": "x2",
    "version": 1,
    "suffix": "x2_v1_200_MLPClassifier",
    "timestamp": "2025-07-04T17:33:23.118592"
  },
  "pca_info": {
    "n_components": 200,
    "explained_variance_ratio": 0.7482720870582513
  },
  "metrics": {
    "train": {
      "f1": 0.9991223915113887,
      "f1_score": 0.9988285825849278,
      "precision": 0.9994139480367259,
      "recall": 0.9982439024390244,
      "accuracy": 0.9992207539205819,
      "classification_report": {
        "0": {
          "precision": 0.9991245561986285,
          "recall": 0.9997080149885639,
          "f1-score": 0.9994162004378496,
          "support": 20549.0
        },
        "1": {
          "precision": 0.9994139480367259,
          "recall": 0.9982439024390244,
          "f1-score": 0.9988285825849278,
          "support": 10250.0
        },
        "accuracy": 0.9992207539205819,
        "macro avg": {
          "precision": 0.9992692521176771,
          "recall": 0.9989759587137941,
          "f1-score": 0.9991223915113887,
          "support": 30799.0
        },
        "weighted avg": {
          "precision": 0.9992208666743093,
          "recall": 0.9992207539205819,
          "f1-score": 0.9992206394458548,
          "support": 30799.0
        }
      },
      "y_pred": "[0 1 0 ... 0 1 0]",
      "y_pred_proba": "[[1.00000000e+00 1.89413767e-12]\n [5.50737385e-07 9.99999449e-01]\n [9.99999988e-01 1.17421421e-08]\n ...\n [9.99995042e-01 4.95847330e-06]\n [1.45736978e-10 1.00000000e+00]\n [9.99994806e-01 5.19400388e-06]]",
      "auc_roc": 0.9999689308956936,
      "tpr": 0.9982439024390244,
      "fpr": 0.0002919850114360796,
      "g_mean": 0.998975690485887
    },
    "test": {
      "f1": 0.9978126156248066,
      "f1_score": 0.9970890743256355,
      "precision": 0.9996108949416342,
      "recall": 0.994579945799458,
      "accuracy": 0.9980519480519481,
      "classification_report": {
        "0": {
          "precision": 0.997270955165692,
          "recall": 0.9998045729919874,
          "f1-score": 0.9985361569239778,
          "support": 5117.0
        },
        "1": {
          "precision": 0.9996108949416342,
          "recall": 0.994579945799458,
          "f1-score": 0.9970890743256355,
          "support": 2583.0
        },
        "accuracy": 0.9980519480519481,
        "macro avg": {
          "precision": 0.9984409250536631,
          "recall": 0.9971922593957228,
          "f1-score": 0.9978126156248066,
          "support": 7700.0
        },
        "weighted avg": {
          "precision": 0.9980558985996215,
          "recall": 0.9980519480519481,
          "f1-score": 0.9980507264887158,
          "support": 7700.0
        }
      },
      "y_pred": "[1 0 0 ... 1 0 0]",
      "y_pred_proba": "[[2.77485379e-04 9.99722515e-01]\n [1.00000000e+00 8.96876360e-12]\n [9.99999862e-01 1.37807244e-07]\n ...\n [2.35855580e-09 9.99999998e-01]\n [9.99996060e-01 3.93979017e-06]\n [9.99999999e-01 1.13502491e-09]]",
      "auc_roc": 0.9998511788909173,
      "tpr": 0.994579945799458,
      "fpr": 0.00019542700801250732,
      "g_mean": 0.9971888376914481
    }
  },
  "model_info": {
    "best_params": {
      "activation": "relu",
      "alpha": 0.0001,
      "hidden_layer_sizes": [
        100
      ],
      "learning_rate_init": 0.01,
      "max_iter": 1000,
      "solver": "adam"
    },
    "best_cv_score": 0.9938738904450393,
    "trained_model": "MLPClassifier(early_stopping=True, learning_rate_init=0.01, max_iter=1000,\n              random_state=0, validation_fraction=0.3)"
  },
  "paths": {
    "plots": {}
  },
  "additional_info": {}
}